## Bit encoding ##

So my first post is going to be about something I did in my master's thesis, bit encoding. Before I talk about the specific encoding I used, let me discuss some of the uses of encoding, and of course a small section on what encoding is.

#### So what is encoding? ####
According to [Wikipedia](https://en.wikipedia.org/wiki/Encoding), encoding (or code) is a system of rules to convert information. One encoding system that almost everyone have heard of is  [morse code](http://morsecode.scphillips.com/morse.html). Morse code is a system of rules that encodes and decodes the alphabet into sound or light signals. Encoding here means, for examlpe, going from the letter A to morse ( short long ), and decoding is the reverse, translating from morse (short long) to the lettar A. Basically you are translating data from one form into another.



From here on out we are going to talk about this snippet of C++ code:

```c++
uint8_t* encode(uint64_t value) {
  uint8_t* out[10];
  int i = 0;
  do {
    out[i++] = (uint8_t)(value & 0x7F);
    value >>= 7;
  } while(value);
  out[i - 1] |= 0x80;
  return out;
}
```

We will talk about what all the different pieces does in a bit, but first a high level overview.

What we are trying to do is reduce the amount bits used for a 64 bit unsigned integer, for storage or transfere over the network in a fast and efficient way. The main principle in the algorithm is that most 64 bit values do not use all 64 bits. For example

```c++
uint64_t example = 1;
```

will be stored in memory as

```
00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000001
```

What we see here is 63 bits of unused information. What if we only try to transmit the relevant information? That is what this algorithm is trying to do.

 